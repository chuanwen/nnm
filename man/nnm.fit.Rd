% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nnm.R
\name{nnm.fit}
\alias{nnm.fit}
\title{fit a (deep) neuron network model. It's a wrap of the DNN class.}
\usage{
nnm.fit(
  x,
  y,
  layerSpecs,
  weights,
  family = c("gaussian", "poisson", "multinomial"),
  nEpoch = 5,
  batchSize = 100,
  learningRate = 0.25,
  verbose = 0
)
}
\arguments{
\item{x}{numeric matrix, of dimension nobs x nvars; each row is an observation vector.}

\item{y}{response variable (vector or matrix). Quantitative for
'family="gaussian"', or 'family="poisson"' (non-negative counts).
For 'family="multinomial"', should be either a factor/character vector, or
a matrix of N-Classes cols.}

\item{layerSpecs}{either a list of layer specs, or a (composite) layer
objectect (e.g. a Sequential or DAG layer). See \code{\link{Sequential}}
for how to specify a sequential of layers,}

\item{weights}{weight of the obs, default 1 for each and every observation.}

\item{family}{Response type, should be one of c("gaussian", "poisson",
"multinomial"). If not specified, will be inferred from class(y).}

\item{nEpoch}{number of times to train over the whole data, default 5.}

\item{batchSize}{number of observations per train batch, default 100.}

\item{learningRate}{a float between 0 and 1, default 0.25.}

\item{verbose}{default 0, if >= 1 will print out loss during training.}
}
\description{
fit a (deep) neuron network model. It's a wrap of the DNN class.
}
\examples{
x = iris[, 1:4]
y = iris[, 5]
mod = nnm.fit(x, y, list(Dense(4, 3, Activation.Identity), Softmax))
mod

# example model for MNIST data
mnist <- LoadMnist("/home/ccw/learning/data/mnist")
train <- mnist$train
test <- mnist$test
mod = nnm.fit(train$x, train$y, list(Dense(784, 15),
  Dense(15, 10, Activation.Identity), Softmax), nEpoch=1)
# accuracy on train set
mean(mod$y == mod$fitted)
# accuracy on test set
mean(test$y == predict(mod, test$x, type="label"))

}
