{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(nnm)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST with DNN (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Sequential Layer 784 -> 10 \n",
       "   | Dense: 784 -> 128 ReLU \n",
       "   | Dropout, keepProb =  0.8 \n",
       "   | Dense: 128 -> 10 Identity \n",
       "   | Softmax, numClasses =  10 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist <- LoadMnist()\n",
    "train <- mnist$train\n",
    "test <- mnist$test\n",
    "layerSpec <- Sequential(\n",
    "  Dense(784, 128),\n",
    "  Dropout(128, keepProb=0.8),\n",
    "  Dense(128, 10, Activation.Identity),\n",
    "  Softmax)\n",
    "layerSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1 total loss =  230.4417 \n",
      "iter  101 total loss =  54.82057 \n",
      "iter  201 total loss =  52.64025 \n",
      "iter  301 total loss =  36.74286 \n",
      "iter  401 total loss =  27.63097 \n",
      "iter  501 total loss =  21.57751 \n",
      "iter  601 total loss =  30.33582 \n",
      "iter  701 total loss =  20.93598 \n",
      "iter  801 total loss =  20.97486 \n",
      "iter  901 total loss =  23.93861 \n",
      "iter  1001 total loss =  32.07045 \n",
      "iter  1101 total loss =  25.03486 \n",
      "iter  1201 total loss =  32.53601 \n",
      "iter  1301 total loss =  13.55056 \n",
      "iter  1401 total loss =  17.18514 \n",
      "iter  1501 total loss =  14.77319 \n",
      "iter  1601 total loss =  20.81168 \n",
      "iter  1701 total loss =  17.39375 \n",
      "iter  1801 total loss =  12.75528 \n",
      "iter  1901 total loss =  14.53266 \n",
      "iter  2001 total loss =  14.95641 \n",
      "iter  2101 total loss =  16.14138 \n",
      "iter  2201 total loss =  16.49437 \n",
      "iter  2301 total loss =  5.623276 \n",
      "iter  2401 total loss =  11.93723 \n",
      "iter  2501 total loss =  7.739242 \n",
      "iter  2601 total loss =  10.45309 \n",
      "iter  2701 total loss =  17.25861 \n",
      "iter  2801 total loss =  14.78283 \n",
      "iter  2901 total loss =  20.22743 \n"
     ]
    }
   ],
   "source": [
    "modTime <- system.time(\n",
    "    mod <- nnm(train$x, train$y, layerSpec, verbose=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  system elapsed \n",
      " 88.377   0.968  89.346 \n"
     ]
    }
   ],
   "source": [
    "print(modTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters:  101770 \n",
      "accuracy =  0.9692 \n"
     ]
    }
   ],
   "source": [
    "# number of parameters in the model\n",
    "cat(\"num of parameters: \", NumParameters(mod), \"\\n\")\n",
    "\n",
    "# accuracy on test set\n",
    "cat(\"accuracy = \", mean(test$y == predict(mod, test$x, type=\"label\")), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST with Directed acyclic graph (DAG)\n",
    "\n",
    "We demo a simple DAG with residual connections. This DAG\n",
    "has similar performance to the above full-connection graph\n",
    "but with only about half parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Directed Acycle Graph 784 -> 10 \n",
       "   | node 1:  Dense: 784 -> 64 ReLU \n",
       "   | node 2:  Dropout, keepProb =  0.8 \n",
       "   | node 3:  Dense: 64 -> 32 ReLU \n",
       "   | node 4:  Dense: 32 -> 16 ReLU \n",
       "   | node 5:  Dense: 48 -> 10 Identity \n",
       "   | node 6:  Softmax, numClasses =  10 \n",
       "   | edge: node 1 -> node 2 \n",
       "   | edge: node 2 -> node 3 \n",
       "   | edge: node 3 -> node 4 \n",
       "   | edge: node 4 -> node 5 \n",
       "   | edge: node 3 -> node 5 \n",
       "   | edge: node 5 -> node 6 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers <- list(\n",
    "  Dense(784, 64),\n",
    "  Dropout(64, keepProb=0.8),\n",
    "  Dense(64, 32),\n",
    "  Dense(32, 16),\n",
    "  Dense(48, 10, Activation.Identity),\n",
    "  Softmax(10))\n",
    "edges <- c(1, 2,\n",
    "           2, 3,\n",
    "           3, 4,\n",
    "           4, 5,\n",
    "           3, 5,\n",
    "           5, 6)\n",
    "dag <- DAG(layers, edges)\n",
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1 total loss =  230.2588 \n",
      "iter  101 total loss =  230.0958 \n",
      "iter  201 total loss =  228.9939 \n",
      "iter  301 total loss =  140.5326 \n",
      "iter  401 total loss =  97.68631 \n",
      "iter  501 total loss =  62.97778 \n",
      "iter  601 total loss =  42.8144 \n",
      "iter  701 total loss =  31.89813 \n",
      "iter  801 total loss =  36.41382 \n",
      "iter  901 total loss =  39.09989 \n",
      "iter  1001 total loss =  22.98892 \n",
      "iter  1101 total loss =  18.75162 \n",
      "iter  1201 total loss =  19.77463 \n",
      "iter  1301 total loss =  10.29939 \n",
      "iter  1401 total loss =  34.59066 \n",
      "iter  1501 total loss =  17.2062 \n",
      "iter  1601 total loss =  26.68019 \n",
      "iter  1701 total loss =  10.97525 \n",
      "iter  1801 total loss =  23.90741 \n",
      "iter  1901 total loss =  12.78519 \n",
      "iter  2001 total loss =  21.66174 \n",
      "iter  2101 total loss =  21.60756 \n",
      "iter  2201 total loss =  28.62931 \n",
      "iter  2301 total loss =  31.64293 \n",
      "iter  2401 total loss =  20.0359 \n",
      "iter  2501 total loss =  16.49298 \n",
      "iter  2601 total loss =  25.57688 \n",
      "iter  2701 total loss =  19.76294 \n",
      "iter  2801 total loss =  8.166451 \n",
      "iter  2901 total loss =  25.08339 \n"
     ]
    }
   ],
   "source": [
    "modTime2 <- system.time(\n",
    "dagMod <- nnm(train$x, train$y, dag, verbose=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  system elapsed \n",
      " 61.422   0.828  62.248 \n"
     ]
    }
   ],
   "source": [
    "print(modTime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of parameters:  53338 \n",
      "accuracy =  0.9604 \n"
     ]
    }
   ],
   "source": [
    "# number of parameters in the model\n",
    "cat(\"num of parameters: \", NumParameters(dagMod), \"\\n\")\n",
    "\n",
    "# accuracy on test set\n",
    "cat(\"accuracy = \", mean(test$y == predict(dagMod, test$x, type=\"label\")), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of embedding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingCols: x2, x3.\n",
       "numEmbeddingDims: 2, 4.\n",
       "\n",
       "DNN, type = regression \n",
       "Loss:  MSE \n",
       " Sequential Layer 3 -> 1 \n",
       "   | Paralleled Layers 3 -> 7 \n",
       "   |   | Identity 1 -> 1 \n",
       "   |   | Paralleled Layers 2 -> 6 \n",
       "   |   |   | Embedding: 1 -> 2 \n",
       "   |   |   | Embedding: 1 -> 4 \n",
       "   | Sequential Layer 7 -> 1 \n",
       "   |   | Dense: 7 -> 2 ReLU \n",
       "   |   | Dense: 2 -> 1 Identity \n",
       "sample response and predictions\n",
       "            y       fitted\n",
       "1   1.9071253  0.842755239\n",
       "2   1.3252411  2.176316829\n",
       "3   1.4663919 -0.103369807\n",
       "4  -0.9201589 -0.507212289\n",
       "5   0.5934152  1.322064758\n",
       "6  -0.5463789  1.170592107\n",
       "7  -1.1221130 -0.022001247\n",
       "8  -1.7532354 -1.367446041\n",
       "9   0.9627592  1.547368443\n",
       "10 -1.2764272  0.008830899\n",
       "11 -1.6930950 -0.352822402\n",
       "12 -1.0440762 -0.234526676\n",
       "13 -0.8179057  0.318121617\n",
       "14 -1.2137760 -0.878978979\n",
       "15 -1.2540897 -0.748568565\n",
       "16 -0.2041840  0.968665061\n",
       "17  0.5145738  0.950052371\n",
       "18 -0.1714448 -1.798866429\n",
       "19 -0.0995794 -0.703402988\n",
       "20 -0.8884164 -0.942933604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n <- 1000\n",
    "x <- data.frame(x1 = rnorm(n),\n",
    "                x2 = sample(letters, size=n, replace=TRUE),\n",
    "                x3 = sample(letters, size=n, replace=TRUE))\n",
    "y <- x$x1 + x$x2 %in% c(\"a\", \"d\")  + rnorm(n)\n",
    "embeddingCols <- c(\"x2\" ,\"x3\")\n",
    "embeddingDims <- c(2, 4)\n",
    "layerSpecs <- list(Dense(1 + sum(embeddingDims), 2), Dense(2, 1, Activation.Identity))\n",
    "mod2 <- nnm(x, y, layerSpecs, embeddingCols, embeddingDims)\n",
    "mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 1 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.7483163</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 1 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t 0.7483163\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 1 × 1 of type dbl\n",
       "\n",
       "| 0.7483163 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] 0.7483163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " cor(y, predict(mod2, x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
