{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "    library(nnm)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST with DNN (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Sequential Layer 784 -> 10 \n",
       "   | Dense: 784 -> 128 ReLU \n",
       "   | Dropout, keepProb =  0.8 \n",
       "   | Dense: 128 -> 10 Identity \n",
       "   | Softmax, numClasses =  10 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist <- LoadMnist()\n",
    "train <- mnist$train\n",
    "test <- mnist$test\n",
    "layerSpec <- Sequential(\n",
    "  Dense(784, 128),\n",
    "  Dropout(128, keepProb=0.8),\n",
    "  Dense(128, 10, Activation.Identity),\n",
    "  Softmax)\n",
    "layerSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1 total loss =  230.283 \n",
      "iter  101 total loss =  62.13019 \n",
      "iter  201 total loss =  44.5404 \n",
      "iter  301 total loss =  34.62881 \n",
      "iter  401 total loss =  37.23956 \n",
      "iter  501 total loss =  21.77938 \n",
      "iter  601 total loss =  16.0151 \n",
      "iter  701 total loss =  29.71946 \n",
      "iter  801 total loss =  38.90523 \n",
      "iter  901 total loss =  17.81867 \n",
      "iter  1001 total loss =  17.86292 \n",
      "iter  1101 total loss =  13.97953 \n",
      "iter  1201 total loss =  21.40744 \n",
      "iter  1301 total loss =  17.84026 \n",
      "iter  1401 total loss =  19.79315 \n",
      "iter  1501 total loss =  12.29914 \n",
      "iter  1601 total loss =  15.76222 \n",
      "iter  1701 total loss =  17.89719 \n",
      "iter  1801 total loss =  10.90802 \n",
      "iter  1901 total loss =  12.09158 \n",
      "iter  2001 total loss =  8.551515 \n",
      "iter  2101 total loss =  14.64607 \n",
      "iter  2201 total loss =  19.91964 \n",
      "iter  2301 total loss =  10.36869 \n",
      "iter  2401 total loss =  9.112068 \n",
      "iter  2501 total loss =  19.04041 \n",
      "iter  2601 total loss =  8.175551 \n",
      "iter  2701 total loss =  9.280241 \n",
      "iter  2801 total loss =  14.18195 \n",
      "iter  2901 total loss =  4.127248 \n"
     ]
    }
   ],
   "source": [
    "modTime <- system.time(\n",
    "    mod <- nnm(train$x, train$y, layerSpec, verbose=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  system elapsed \n",
      " 96.803   1.084  97.901 \n"
     ]
    }
   ],
   "source": [
    "print(modTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9692 \n"
     ]
    }
   ],
   "source": [
    "# accuracy on test set\n",
    "cat(\"accuracy = \", mean(test$y == predict(mod, test$x, type=\"label\")), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST with Directed acyclic graph (DAG)\n",
    "\n",
    "We demo a simple DAG with residual connections. This DAG\n",
    "has similar performance to the above full-connection graph\n",
    "but with only about half parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Directed Acycle Graph 784 -> 10 \n",
       "   | node 1:  Dense: 784 -> 64 ReLU \n",
       "   | node 2:  Dropout, keepProb =  0.8 \n",
       "   | node 3:  Dense: 64 -> 32 ReLU \n",
       "   | node 4:  Dense: 32 -> 16 ReLU \n",
       "   | node 5:  Dense: 48 -> 10 Identity \n",
       "   | node 6:  Softmax, numClasses =  10 \n",
       "   | edge: node 1 -> node 2 \n",
       "   | edge: node 2 -> node 3 \n",
       "   | edge: node 3 -> node 4 \n",
       "   | edge: node 4 -> node 5 \n",
       "   | edge: node 3 -> node 5 \n",
       "   | edge: node 5 -> node 6 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers <- list(\n",
    "  Dense(784, 64),\n",
    "  Dropout(64, keepProb=0.8),\n",
    "  Dense(64, 32),\n",
    "  Dense(32, 16),\n",
    "  Dense(48, 10, Activation.Identity),\n",
    "  Softmax(10))\n",
    "edges <- c(1, 2,\n",
    "           2, 3,\n",
    "           3, 4,\n",
    "           4, 5,\n",
    "           3, 5,\n",
    "           5, 6)\n",
    "dag <- DAG(layers, edges)\n",
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1 total loss =  230.2648 \n",
      "iter  101 total loss =  230.3848 \n",
      "iter  201 total loss =  227.8851 \n",
      "iter  301 total loss =  134.9185 \n",
      "iter  401 total loss =  91.72305 \n",
      "iter  501 total loss =  59.4139 \n",
      "iter  601 total loss =  48.71088 \n",
      "iter  701 total loss =  23.96979 \n",
      "iter  801 total loss =  43.81935 \n",
      "iter  901 total loss =  26.50421 \n",
      "iter  1001 total loss =  36.47608 \n",
      "iter  1101 total loss =  20.68648 \n",
      "iter  1201 total loss =  26.20561 \n",
      "iter  1301 total loss =  13.14982 \n",
      "iter  1401 total loss =  25.17576 \n",
      "iter  1501 total loss =  18.39282 \n",
      "iter  1601 total loss =  22.62202 \n",
      "iter  1701 total loss =  23.18602 \n",
      "iter  1801 total loss =  16.77054 \n",
      "iter  1901 total loss =  42.64111 \n",
      "iter  2001 total loss =  8.084379 \n",
      "iter  2101 total loss =  20.28254 \n",
      "iter  2201 total loss =  11.74359 \n",
      "iter  2301 total loss =  10.39085 \n",
      "iter  2401 total loss =  19.70342 \n",
      "iter  2501 total loss =  32.49685 \n",
      "iter  2601 total loss =  11.35954 \n",
      "iter  2701 total loss =  15.22414 \n",
      "iter  2801 total loss =  20.78675 \n",
      "iter  2901 total loss =  30.154 \n"
     ]
    }
   ],
   "source": [
    "modTime2 <- system.time(\n",
    "dagMod <- nnm(train$x, train$y, dag, verbose=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  system elapsed \n",
      " 65.075   0.956  66.049 \n"
     ]
    }
   ],
   "source": [
    "print(modTime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9653 \n"
     ]
    }
   ],
   "source": [
    "# accuracy on test set\n",
    "cat(\"accuracy = \", mean(test$y == predict(dagMod, test$x, type=\"label\")), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of embedding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingCols: x2, x3.\n",
       "numEmbeddingDims: 2, 4.\n",
       "\n",
       "DNN, type = regression \n",
       "Loss:  MSE \n",
       " Sequential Layer 3 -> 1 \n",
       "   | Paralleled Layers 3 -> 7 \n",
       "   |   | Identity 1 -> 1 \n",
       "   |   | Paralleled Layers 2 -> 6 \n",
       "   |   |   | Embedding: 1 -> 2 \n",
       "   |   |   | Embedding: 1 -> 4 \n",
       "   | Sequential Layer 7 -> 1 \n",
       "   |   | Dense: 7 -> 2 ReLU \n",
       "   |   | Dense: 2 -> 1 Identity \n",
       "sample response and predictions\n",
       "              y      fitted\n",
       "1   1.634137657 -0.18547513\n",
       "2  -0.717665895  0.69230233\n",
       "3  -1.728895119 -2.14726326\n",
       "4  -1.284986898 -1.26461826\n",
       "5   0.005282155  0.24517230\n",
       "6   1.057496575  0.53635903\n",
       "7   1.336650211  0.22451976\n",
       "8  -0.879975161 -0.16794991\n",
       "9   1.146940030  1.10987720\n",
       "10 -1.957243947 -1.77471453\n",
       "11 -1.931963792 -1.37772841\n",
       "12 -1.774479063 -0.23718287\n",
       "13 -0.284182205  0.04057911\n",
       "14 -0.736987279 -0.78516626\n",
       "15 -0.697900694 -1.40473964\n",
       "16 -0.985800362 -0.83597289\n",
       "17  1.280547374  0.95029142\n",
       "18  0.884801306  0.94554062\n",
       "19 -0.243123261 -1.11471176\n",
       "20 -0.793728848 -0.48605138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n <- 1000\n",
    "x <- data.frame(x1 = rnorm(n),\n",
    "                x2 = sample(letters, size=n, replace=TRUE),\n",
    "                x3 = sample(letters, size=n, replace=TRUE))\n",
    "y <- x$x1 + x$x2 %in% c(\"a\", \"d\")  + rnorm(n)\n",
    "embeddingCols <- c(\"x2\" ,\"x3\")\n",
    "embeddingDims <- c(2, 4)\n",
    "layerSpecs <- list(Dense(1 + sum(embeddingDims), 2), Dense(2, 1, Activation.Identity))\n",
    "mod2 <- nnm(x, y, layerSpecs, embeddingCols, embeddingDims)\n",
    "mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 1 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.7048263</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 1 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t 0.7048263\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 1 × 1 of type dbl\n",
       "\n",
       "| 0.7048263 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] 0.7048263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " cor(y, predict(mod2, x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
